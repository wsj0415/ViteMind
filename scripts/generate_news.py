import requests
import json
import os
from datetime import datetime
import feedparser

# é…ç½®
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY")
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
MODEL_NAME = "google/gemini-2.0-flash-exp:free" # ä½¿ç”¨å…è´¹æ¨¡å‹

# æ•°æ®æº
RSS_FEEDS = [
    "https://export.arxiv.org/rss/cs.AI", # Official Arxiv RSS
    "https://hnrss.org/newest?q=AI+LLM+GPT", # Hacker News AI related
]

def fetch_rss_data():
    articles = []
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    for feed_url in RSS_FEEDS:
        print(f"Fetching {feed_url}...")
        try:
            # Use requests to fetch with headers to avoid 403 Forbidden
            response = requests.get(feed_url, headers=headers, timeout=30)
            if response.status_code != 200:
                print(f"Failed to fetch {feed_url}, status code: {response.status_code}")
                continue
                
            feed = feedparser.parse(response.content)
            
            if not feed.entries:
                print(f"No entries found in {feed_url}")
                continue
                
            print(f"Found {len(feed.entries)} entries in {feed_url}")
            for entry in feed.entries[:5]: # æ¯ä¸ªæºåªå–å‰5æ¡
                articles.append({
                    "title": entry.title,
                    "link": entry.link,
                    "summary": entry.get("summary", "")[:200] # æˆªå–æ‘˜è¦
                })
        except Exception as e:
            print(f"Error fetching {feed_url}: {e}")
    return articles

def summarize_with_ai(articles):
    if not articles:
        return "ä»Šæ—¥æ— é‡å¤§ AI æ–°é—»ã€‚"

    # æ„å»º Prompt
    news_text = "\n".join([f"- [{a['title']}]({a['link']}): {a['summary']}" for a in articles])
    prompt = f"""
    ä½ æ˜¯ä¸“ä¸šçš„ AI è¡Œä¸šåˆ†æå¸ˆã€‚è¯·é˜…è¯»ä»¥ä¸‹åŸå§‹æ–°é—»åˆ—è¡¨ï¼Œç­›é€‰å‡º 5-8 æ¡æœ€æœ‰ä»·å€¼çš„ AI æŠ€æœ¯è¿›å±•æˆ–è¡Œä¸šåŠ¨æ€ã€‚
    
    è¦æ±‚ï¼š
    1. ä½¿ç”¨ä¸­æ–‡è¾“å‡ºã€‚
    2. æ ¼å¼ä¸º Markdown åˆ—è¡¨ã€‚
    3. æ¯æ¡æ–°é—»åŒ…å«ä¸€ä¸ª Emoji å›¾æ ‡ï¼Œæ ‡é¢˜ï¼ˆå¸¦åŸæ–‡é“¾æ¥ï¼‰ï¼Œä»¥åŠä¸€å¥è¯çš„æ·±åº¦ç‚¹è¯„ã€‚
    4. é£æ ¼ä¸“ä¸šã€ç®€æ´ã€æœ‰æ´è§ã€‚
    5. æœ€ååŠ ä¸€æ®µâ€œä»Šæ—¥æ€»ç»“â€ã€‚

    åŸå§‹æ–°é—»ï¼š
    {news_text}
    """

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://vitemind.com", 
    }
    
    data = {
        "model": MODEL_NAME,
        "messages": [{"role": "user", "content": prompt}]
    }

    try:
        response = requests.post(OPENROUTER_URL, headers=headers, json=data)
        response.raise_for_status()
        return response.json()['choices'][0]['message']['content']
    except Exception as e:
        print(f"AI Generation Error: {e}")
        return f"AI ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚\n\nåŸå§‹æ•°æ®ï¼š\n{news_text}"

def save_to_markdown(content):
    today = datetime.now().strftime("%Y-%m-%d")
    filename = f"docs/news/{today}.md"
    
    md_content = f"""---
title: AI æƒ…æŠ¥å±€ - {today}
---

# ğŸ¤– AI æƒ…æŠ¥å±€ ({today})

> æœ¬æ—¥æŠ¥ç”± GitHub Actions è‡ªåŠ¨æŠ“å–ï¼ŒGemini AI æ•´ç†ç”Ÿæˆã€‚

{content}

---
*[ViteMind](/) - æ„å»ºä½ çš„æ•°å­—èµ„äº§é‡‘åº“*
"""
    
    with open(filename, "w", encoding="utf-8") as f:
        f.write(md_content)
    print(f"Saved to {filename}")

if __name__ == "__main__":
    if not OPENROUTER_API_KEY:
        print("Error: OPENROUTER_API_KEY not found.")
        # For local testing without key, maybe generate dummy data or exit
        exit(1)

    print("Starting AI News Generator...")
    raw_articles = fetch_rss_data()
    print(f"Fetched {len(raw_articles)} articles.")
    
    ai_summary = summarize_with_ai(raw_articles)
    save_to_markdown(ai_summary)
    print("Done.")
