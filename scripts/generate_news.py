import requests
import json
import os
from datetime import datetime
import feedparser

# é…ç½®
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY")
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
MODEL_NAME = "xiaomi/mimo-v2-flash:free" # ç”¨æˆ·æŒ‡å®šå…è´¹æ¨¡å‹

# æ•°æ®æº
RSS_FEEDS = [
    "https://hnrss.org/newest?q=AI", # ç®€åŒ–æŸ¥è¯¢å‚æ•°
]

def fetch_rss_data():
    articles = []
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    for feed_url in RSS_FEEDS:
        print(f"Fetching {feed_url}...")
        try:
            response = requests.get(feed_url, headers=headers, timeout=30)
            if response.status_code != 200:
                print(f"Failed to fetch {feed_url}, status code: {response.status_code}")
                continue
                
            feed = feedparser.parse(response.content)
            
            print(f"Found {len(feed.entries)} entries in {feed_url}")
            for entry in feed.entries[:5]: # æ¯ä¸ªæºåªå–å‰5æ¡
                # ä½¿ç”¨ Jina Reader è¯»å–å…¨æ–‡
                jina_url = f"https://r.jina.ai/{entry.link}"
                print(f"Reading with Jina: {jina_url}")
                try:
                    # Jina å¯èƒ½ä¼šå¯¹æŸäº› User-Agent æ•æ„Ÿï¼Œå°è¯•ä¸å¸¦ç‰¹æ®Š UA æˆ–ä½¿ç”¨é»˜è®¤
                    jina_resp = requests.get(jina_url, timeout=30) 
                    
                    if jina_resp.status_code == 200 and "403 Forbidden" not in jina_resp.text:
                        content = jina_resp.text[:2000] # å¢åŠ æˆªå–é•¿åº¦ï¼Œè·å–æ›´å¤šä¿¡æ¯
                    else:
                        print(f"Jina returned {jina_resp.status_code}, falling back to summary.")
                        content = entry.get("summary", "")
                except Exception as e:
                    print(f"Jina read failed: {e}")
                    content = entry.get("summary", "")

                # å¦‚æœå†…å®¹å¤ªçŸ­ï¼ˆå¯èƒ½æ˜¯ç©ºæˆ–é”™è¯¯ï¼‰ï¼Œä¹Ÿå›é€€åˆ°æ‘˜è¦
                if len(content) < 50:
                     content = entry.get("summary", "")

                articles.append({
                    "title": entry.title,
                    "link": entry.link,
                    "summary": content 
                })
        except Exception as e:
            print(f"Error fetching {feed_url}: {e}")
    return articles

def summarize_with_ai(articles):
    if not articles:
        return "ä»Šæ—¥æ— é‡å¤§ AI æ–°é—»ã€‚"

    # æ„å»º Prompt
    news_text = "\n".join([f"- [{a['title']}]({a['link']}): {a['summary']}" for a in articles])
    prompt = f"""
    ä½ æ˜¯ä¸“ä¸šçš„ AI è¡Œä¸šåˆ†æå¸ˆã€‚è¯·é˜…è¯»ä»¥ä¸‹åŸå§‹æ–°é—»åˆ—è¡¨ï¼Œç­›é€‰å‡º 5-8 æ¡æœ€æœ‰ä»·å€¼çš„ AI æŠ€æœ¯è¿›å±•æˆ–è¡Œä¸šåŠ¨æ€ã€‚
    
    è¦æ±‚ï¼š
    1. ä½¿ç”¨ä¸­æ–‡è¾“å‡ºã€‚
    2. æ ¼å¼ä¸º Markdown åˆ—è¡¨ã€‚
    3. æ¯æ¡æ–°é—»åŒ…å«ä¸€ä¸ª Emoji å›¾æ ‡ï¼Œæ ‡é¢˜ï¼ˆå¸¦åŸæ–‡é“¾æ¥ï¼‰ï¼Œä»¥åŠä¸€å¥è¯çš„æ·±åº¦ç‚¹è¯„ã€‚
    4. é£æ ¼ä¸“ä¸šã€ç®€æ´ã€æœ‰æ´è§ã€‚
    5. æœ€ååŠ ä¸€æ®µâ€œä»Šæ—¥æ€»ç»“â€ã€‚

    åŸå§‹æ–°é—»ï¼š
    {news_text}
    """

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://vitemind.com", 
    }
    
    data = {
        "model": MODEL_NAME,
        "messages": [{"role": "user", "content": prompt}]
    }

    try:
        response = requests.post(OPENROUTER_URL, headers=headers, json=data)
        response.raise_for_status()
        return response.json()['choices'][0]['message']['content']
    except Exception as e:
        print(f"AI Generation Error: {e}")
        return f"AI ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚\n\nåŸå§‹æ•°æ®ï¼š\n{news_text}"

def save_to_markdown(content):
    today = datetime.now().strftime("%Y-%m-%d")
    index_file = "docs/news/index.md"
    
    new_entry = f"""
## {today} AI æ—¥æŠ¥

{content}

---
"""
    
    try:
        with open(index_file, "r", encoding="utf-8") as f:
            existing_content = f.read()
    except FileNotFoundError:
        existing_content = "# ğŸ¤– AI æƒ…æŠ¥å±€\n\nè¿™é‡Œæ±‡é›†äº†ç”± AI è‡ªåŠ¨æ•´ç†çš„æ¯æ—¥è¡Œä¸šåŠ¨æ€ã€‚\n\n---\n"

    # æ‰¾åˆ°æ’å…¥ç‚¹ï¼ˆåœ¨ --- ä¹‹åï¼‰
    split_marker = "---\n"
    parts = existing_content.split(split_marker, 1)
    
    if len(parts) == 2:
        header, body = parts
        updated_content = f"{header}{split_marker}\n{new_entry}\n{body}"
    else:
        updated_content = existing_content + "\n" + new_entry

    with open(index_file, "w", encoding="utf-8") as f:
        f.write(updated_content)
    print(f"Updated {index_file}")

if __name__ == "__main__":
    if not OPENROUTER_API_KEY:
        print("Error: OPENROUTER_API_KEY not found.")
        # For local testing without key, maybe generate dummy data or exit
        exit(1)

    print("Starting AI News Generator...")
    raw_articles = fetch_rss_data()
    print(f"Fetched {len(raw_articles)} articles.")
    
    ai_summary = summarize_with_ai(raw_articles)
    save_to_markdown(ai_summary)
    print("Done.")
